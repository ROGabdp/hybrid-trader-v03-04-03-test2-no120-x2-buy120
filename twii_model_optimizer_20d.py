# -*- coding: utf-8 -*-
"""
TWII 20 æ—¥é æ¸¬æ¨¡å‹åƒæ•¸å„ªåŒ–è…³æœ¬ (Hyperparameter Optimizer)
é‡å° 2000-01-01 ~ 2022-12-31 é•·é€±æœŸæ•¸æ“šå°‹æ‰¾æœ€ä½³åƒæ•¸

æ¸¬è©¦åƒæ•¸çµ„åˆ (Grid Search):
1. LSTM Units: [128, 256]
2. Dropout Rate: [0.2, 0.3, 0.5]
3. Batch Size: [16, 32, 64]

ä½¿ç”¨æ–¹å¼ï¼š
  python twii_model_optimizer_20d.py
"""

import itertools
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import mean_squared_error, r2_score
import twii_model_registry_20d as model_registry

# =============================================================================
# è¨­å®š
# =============================================================================
TRAIN_START = "2000-01-01"
TRAIN_END = "2022-12-31"

# Grid Search å€™é¸åƒæ•¸
PARAM_GRID = {
    'lstm_units': [128, 256],
    'dropout_rate': [0.2, 0.3, 0.5],
    'batch_size': [16, 32, 64]
}

def optimize():
    print("\n" + "=" * 70)
    print("  ğŸš€ TWII T+20 Model Hyperparameter Optimizer")
    print("=" * 70)
    print(f"  Training Range: {TRAIN_START} ~ {TRAIN_END}")
    print(f"  Parameter Grid: {PARAM_GRID}")
    print("=" * 70)

    # 1. æº–å‚™æ•¸æ“š (åªåšä¸€æ¬¡é è™•ç†)
    df = model_registry.download_data_by_date_range(TRAIN_START, TRAIN_END)
    
    # é€™è£¡ split_ratio è¨­ç‚º 0.8 ä¾†é€²è¡Œé©—è­‰ï¼Œä¸ä½¿ç”¨ 0.9 æˆ– 0.99
    # å› ç‚ºæˆ‘å€‘éœ€è¦ä¸€å€‹è¶³å¤ å¤§çš„ Validation Set ä¾†è©•ä¼°åƒæ•¸å¥½å£
    X_train, y_train, X_test, y_test, feature_scaler, target_scaler, _, _, n_features = \
        model_registry.preprocess_for_training(df, train_ratio=0.8)

    print(f"\n[Data] Train samples: {len(X_train)} | Test samples: {len(X_test)}")

    # ç”¢ç”Ÿæ‰€æœ‰çµ„åˆ
    keys, values = zip(*PARAM_GRID.items())
    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]
    
    results = []
    best_r2 = -float('inf')
    best_config = None

    print(f"\n[Optimizer] Starting Grid Search on {len(combinations)} combinations...\n")

    for i, config in enumerate(combinations):
        print("-" * 60)
        print(f"ğŸ”„ Trial {i+1}/{len(combinations)}: {config}")
        
        # è¨­å®šéš¨æ©Ÿç¨®å­é‡ç¾æ€§
        np.random.seed(42)
        tf.random.set_seed(42)

        # å»ºç«‹æ¨¡å‹
        model = model_registry.build_lstm_ssam_model(
            time_steps=model_registry.LOOKBACK,
            n_features=n_features,
            lstm_units=config['lstm_units'],
            dropout_rate=config['dropout_rate']
        )

        # è¨“ç·´
        early_stop = keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,  # å„ªåŒ–æ™‚ç¨å¾®åš´æ ¼ä¸€é»ï¼Œç¯€çœæ™‚é–“
            restore_best_weights=True
        )

        history = model.fit(
            X_train, y_train,
            epochs=30,  # å„ªåŒ–æ™‚ Epochs ç¨å¾®æ¸›å°‘ï¼Œé¿å…å¤ªä¹…
            batch_size=config['batch_size'],
            validation_data=(X_test, y_test),
            callbacks=[early_stop],
            verbose=0  # éœé»˜æ¨¡å¼
        )

        # è©•ä¼°
        y_pred_scaled = model.predict(X_test, verbose=0)
        y_actual = target_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
        y_predicted = target_scaler.inverse_transform(y_pred_scaled).flatten()

        rmse = np.sqrt(mean_squared_error(y_actual, y_predicted))
        r2 = r2_score(y_actual, y_predicted)

        print(f"   ğŸ‘‰ Result: RÂ² = {r2:.4f} | RMSE = {rmse:.2f}")

        results.append({
            **config,
            'r2': r2,
            'rmse': rmse
        })

        if r2 > best_r2:
            best_r2 = r2
            best_config = config
            print(f"   ğŸ† New Best Found!")

    # è¼¸å‡ºç¸½çµ
    print("\n" + "=" * 70)
    print("ğŸ… Optimization Results Summary")
    print("=" * 70)
    
    results_df = pd.DataFrame(results).sort_values(by='r2', ascending=False)
    print(results_df)

    print("\n" + "=" * 70)
    print(f"ğŸ† Best Configuration: {best_config}")
    print(f"   Best RÂ²: {best_r2:.4f}")
    print("=" * 70)
    
    # å»ºè­°æŒ‡ä»¤
    if best_config:
        print("\nTo update `twii_model_registry_20d.py`, use these values:")
        for k, v in best_config.items():
            print(f"  {k.upper()} = {v}")

if __name__ == "__main__":
    optimize()
