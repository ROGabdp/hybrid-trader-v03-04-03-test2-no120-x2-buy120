# -*- coding: utf-8 -*-
"""
================================================================================
Daily Operations V5 - Fixed LSTM ç›¤å¾Œåˆ†æ (No Filter Mode)
================================================================================
ç›¤å¾ŒåŸ·è¡Œè…³æœ¬ - ä½¿ç”¨ V5 æ¨¡å‹ (å°ç¨±çå‹µè¨“ç·´) + å›ºå®š LSTM æ¨¡å‹

**V5 æ¨¡å‹ç‰¹é»**:
- Buy Agent ä½¿ç”¨å°ç¨±çå‹µçµæ§‹è¨“ç·´
- ç„¡ Donchian æ¿¾ç¶²é™åˆ¶ï¼ŒAI å¯è‡ªç”±åˆ¤æ–·è²·å…¥æ™‚æ©Ÿ
- Sell Agent èˆ‡ V4 ç›¸åŒ

**Fixed LSTM ç‰¹é»**:
- ä¸é€²è¡Œæ¯æ—¥é‡è¨“ï¼Œçµæœå®Œå…¨å¯é‡ç¾
- è®€å– backtest_v5_dca_hybrid_no_filter_fixed_lstm.py ç”¢ç”Ÿçš„ lstm_info.json
- ä½¿ç”¨èˆ‡å›æ¸¬ç›¸åŒçš„ LSTM æ¨¡å‹ (T+20, T+5, T+1)
- ä½¿ç”¨ç›¤å¾Œå®Œæ•´è³‡æ–™ (éç›¤ä¸­ä¼°è¨ˆå€¼)

æµç¨‹:
1. è®€å–å›æ¸¬ç”¢ç”Ÿçš„ lstm_info.json å–å¾— Fixed LSTM è·¯å¾‘
2. è¼‰å…¥ Fixed LSTM æ¨¡å‹
3. è®€å–æœ¬åœ° CSV çš„å®Œæ•´ç›¤å¾Œè³‡æ–™
4. ä½¿ç”¨ Fixed LSTM é€²è¡Œç‰¹å¾µå·¥ç¨‹èˆ‡é æ¸¬
5. è¼¸å‡ºçµæœåˆ° daily_runs_v5_fixed/{date}/

ä½œè€…ï¼šPhil Liang (Generated by Gemini)
æ—¥æœŸï¼š2025-12-27
================================================================================
"""

import os
import sys
import glob
import json
import pickle
import subprocess
import shutil
import re
from datetime import datetime, timedelta

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import pandas as pd
from tensorflow import keras

# =============================================================================
# å¼•ç”¨ä¸»ç³»çµ±
# =============================================================================
import ptrl_hybrid_system as core_system

# =============================================================================
# è¨­å®šè·¯å¾‘
# =============================================================================
PROJECT_PATH = os.path.dirname(os.path.abspath(__file__))
DAILY_RUNS_PATH = os.path.join(PROJECT_PATH, 'daily_runs_v5_fixed')  # V5 Fixed LSTM å°ˆç”¨è³‡æ–™å¤¾
CSV_FILE = os.path.join(PROJECT_PATH, 'twii_data_from_2000_01_01.csv')

# RL æ¨¡å‹è·¯å¾‘ (V5)
V5_MODEL_PATH = os.path.join(PROJECT_PATH, 'models_hybrid_v5')

# å›æ¸¬çµæœè·¯å¾‘ (ç”¨æ–¼è®€å–æŒå€‰ç‹€æ…‹å’Œ LSTM è³‡è¨Š)
BACKTEST_RESULTS_PATH = os.path.join(PROJECT_PATH, 'results_backtest_v5_dca_hybrid_no_filter_fixed_lstm')


# =============================================================================
# è¼”åŠ©å‡½å¼: äº’å‹•å¼ CSV é¸å–®
# =============================================================================
def interactive_select_csv(csv_files: list, default_index: int = -1) -> str:
    """
    ä½¿ç”¨æ–¹å‘éµé¸æ“‡ CSV æª”æ¡ˆ
    """
    import msvcrt
    
    if default_index < 0:
        default_index = len(csv_files) + default_index
    
    current = default_index
    
    def render_menu():
        print("\033[H\033[J", end="")  # Clear screen
        print("ğŸ“‚ è«‹é¸æ“‡å›æ¸¬ CSV (â†‘â†“ é¸æ“‡, Enter ç¢ºèª):")
        print("-" * 50)
        for i, f in enumerate(csv_files):
            marker = "  â–¶ " if i == current else "    "
            suffix = " â—€" if i == current else ""
            print(f"{marker}{os.path.basename(f)}{suffix}")
        print("-" * 50)
    
    while True:
        render_menu()
        key = msvcrt.getch()
        
        if key == b'\xe0':  # Arrow key prefix
            key2 = msvcrt.getch()
            if key2 == b'H':  # Up
                current = (current - 1) % len(csv_files)
            elif key2 == b'P':  # Down
                current = (current + 1) % len(csv_files)
        elif key == b'\r':  # Enter
            print(f"\nâœ… å·²é¸æ“‡: {os.path.basename(csv_files[current])}")
            return csv_files[current]


# =============================================================================
# è¼”åŠ©å‡½å¼: è®€å–å›æ¸¬çµæœ
# =============================================================================
def load_latest_backtest_status(backtest_start: str = None, interactive: bool = False) -> dict:
    """
    è®€å–å›æ¸¬ daily_action_strat1 CSV (Strategy 1: Leverage Mode)ï¼Œå–å¾—æŒå€‰ç‹€æ…‹èˆ‡æ§“æ¡¿è³‡è¨Š
    """
    pattern = os.path.join(BACKTEST_RESULTS_PATH, 'daily_action_strat1_*.csv')
    csv_files = sorted(glob.glob(pattern))
    
    if not csv_files:
        print(f"[Warning] æ‰¾ä¸åˆ°å›æ¸¬çµæœ: {pattern}")
        return {'found': False}
    
    # äº’å‹•é¸æ“‡æˆ–è‡ªå‹•é¸æ“‡
    if interactive and len(csv_files) > 1:
        selected_csv = interactive_select_csv(csv_files)
    elif backtest_start:
        start_normalized = backtest_start.replace('-', '')
        matched = [f for f in csv_files if start_normalized in os.path.basename(f)]
        selected_csv = matched[0] if matched else csv_files[-1]
    else:
        selected_csv = csv_files[-1]
    
    print(f"[Backtest] è®€å–: {os.path.basename(selected_csv)}")
    
    df = pd.read_csv(selected_csv)
    last_row = df.iloc[-1]
    
    # è¨ˆç®—ç›®å‰çš„ Peak Price (ä¾ç…§ Strategy 1 é‚è¼¯)
    # é‚è¼¯: éæ§“æ¡¿æ¨¡å¼æ™‚ï¼Œæ›´æ–°æœ€é«˜åƒ¹ï¼›æ§“æ¡¿æ¨¡å¼æ™‚ï¼Œæœ€é«˜åƒ¹é–å®š (ä½œç‚ºå‡ºå ´åŸºæº–)
    current_peak_price = 0
    for _, row in df.iterrows():
        # å¦‚æœ CSV ä¸­æœ‰ leveraged_mode æ¬„ä½
        if 'leveraged_mode' in row:
            is_leveraged = bool(row['leveraged_mode'])
            price = float(row['price'])
            if not is_leveraged:
                if price > current_peak_price:
                    current_peak_price = price
        else:
            # èˆŠç‰ˆ CSV ç›¸å®¹
            current_peak_price = max(current_peak_price, float(row['price']))

    # è®€å– open_positions
    open_pos_file = selected_csv.replace('daily_action_strat1_', 'open_positions_strat1_')
    open_positions = []
    if os.path.exists(open_pos_file):
        pos_df = pd.read_csv(open_pos_file)
        for _, row in pos_df.iterrows():
            open_positions.append({
                'buy_date': row['buy_date'],
                'buy_price': row['buy_price'],
                'shares': row.get('shares', 1),
                'cost': row.get('cost', row['buy_price'])
            })
        print(f"  AI æŒå€‰: {len(open_positions)} ç­†")
    
    # å–å¾—æ§“æ¡¿è³‡è¨Š
    leveraged_mode = bool(last_row.get('leveraged_mode', False))
    current_leverage = float(last_row.get('current_leverage', 1.0))
    positions_2x = int(last_row.get('positions_2x', 0))
    
    result = {
        'found': True,
        'csv_file': os.path.basename(selected_csv),
        'last_date': last_row['date'],
        'dca_positions': int(last_row['dca_position_count']),
        'ai_positions': int(last_row['ai_position_count']),
        'total_positions': int(last_row['total_position_count']),
        'leveraged_mode': leveraged_mode,
        'current_leverage': current_leverage,
        'positions_2x': positions_2x,
        'peak_price': current_peak_price,
        'note': last_row.get('note', ''),
        'open_positions': open_positions
    }
    
    leverage_status = "ğŸ”¥ ON (2x)" if leveraged_mode else "OFF (1x)"
    print(f"  æœ€å¾Œæ—¥æœŸ: {result['last_date']}")
    print(f"  æŒå€‰ç‹€æ…‹: ç¸½{result['total_positions']}å€‰ (DCA{result['dca_positions']} + AI{result['ai_positions']})")
    print(f"  æ§“æ¡¿ç‹€æ…‹: {leverage_status} | Peak: {current_peak_price:,.2f}")
    
    return result


# =============================================================================
# Step 0: å»ºç«‹ç›¤å¾Œå°ˆå±¬å·¥ä½œå€
# =============================================================================
def create_daily_workspace(date_str: str) -> dict:
    ws_path = os.path.join(DAILY_RUNS_PATH, date_str)
    os.makedirs(ws_path, exist_ok=True)
    
    workspace = {
        'root': ws_path,
        'cache': os.path.join(ws_path, 'cache'),
        'reports': os.path.join(ws_path, 'reports'),
    }
    for p in workspace.values():
        os.makedirs(p, exist_ok=True)
    
    print(f"[Workspace] å»ºç«‹å·¥ä½œå€: {ws_path}")
    return workspace


# =============================================================================
# Step 1: è®€å– Fixed LSTM è³‡è¨Šä¸¦è¼‰å…¥æ¨¡å‹
# =============================================================================
def load_lstm_info_from_backtest(csv_file: str = None) -> dict:
    """
    å¾å›æ¸¬çµæœç›®éŒ„è®€å– lstm_info_*.json
    """
    pattern = os.path.join(BACKTEST_RESULTS_PATH, 'lstm_info_*.json')
    json_files = glob.glob(pattern)
    
    if not json_files:
        print(f"[Error] æ‰¾ä¸åˆ° LSTM è³‡è¨Š: {pattern}")
        print(f"        è«‹å…ˆåŸ·è¡Œ: python backtest_v5_dca_hybrid_no_filter_fixed_lstm.py --start 2025-01-02")
        return None
    
    # å¦‚æœæœ‰æŒ‡å®š CSVï¼Œæ ¹æ“š CSV èµ·å§‹æ—¥æœŸå°‹æ‰¾å°æ‡‰çš„ lstm_info
    target_json = None
    if csv_file:
        date_match = re.search(r'strat2_(\d{8})_', csv_file)
        if date_match:
            start_date_str = date_match.group(1)
            start_dt = datetime.strptime(start_date_str, '%Y%m%d')
            train_end_dt = start_dt - timedelta(days=1)
            train_end_str = train_end_dt.strftime('%Y%m%d')
            
            expected_json = os.path.join(BACKTEST_RESULTS_PATH, f'lstm_info_{train_end_str}.json')
            if os.path.exists(expected_json):
                target_json = expected_json
                print(f"[LSTM Info] æ ¹æ“š CSV èµ·å§‹æ—¥ ({start_date_str}) é¸æ“‡å°æ‡‰æ¨¡å‹")
            else:
                print(f"[Warning] æ‰¾ä¸åˆ°å°æ‡‰çš„ lstm_info_{train_end_str}.json")
    
    if target_json is None:
        target_json = sorted(json_files)[-1]
    
    print(f"[LSTM Info] è®€å–: {os.path.basename(target_json)}")
    
    with open(target_json, 'r', encoding='utf-8') as f:
        lstm_info = json.load(f)
    
    print(f"  è¨“ç·´æˆªæ­¢æ—¥: {lstm_info.get('train_end_date', 'N/A')}")
    
    for model_key, info in lstm_info.get('models', {}).items():
        print(f"  {model_key}: {info.get('basename', 'N/A')}")
    
    return lstm_info


def load_fixed_lstm_models(lstm_info: dict) -> bool:
    """
    è¼‰å…¥ Fixed LSTM æ¨¡å‹åˆ° core_system
    """
    try:
        from twii_model_registry_5d import SelfAttention
    except ImportError:
        print("[Error] ç„¡æ³•è¼‰å…¥ SelfAttention é¡åˆ¥")
        return False
    
    print("\n[Model Injection] è¼‰å…¥ Fixed LSTM æ¨¡å‹...")
    
    models = lstm_info.get('models', {})
    loaded_models = {}
    
    for model_key in ['model_1d', 'model_5d', 'model_20d']:
        if model_key not in models:
            print(f"[Error] ç¼ºå°‘ {model_key}")
            return False
        
        model_path = models[model_key]['path']
        
        if not os.path.exists(model_path):
            print(f"[Error] æ‰¾ä¸åˆ°æ¨¡å‹: {model_path}")
            return False
        
        model = keras.models.load_model(model_path, custom_objects={'SelfAttention': SelfAttention})
        
        scaler_feat_path = model_path.replace('model_', 'feature_scaler_').replace('.keras', '.pkl')
        scaler_tgt_path = model_path.replace('model_', 'target_scaler_').replace('.keras', '.pkl')
        meta_path = model_path.replace('model_', 'meta_').replace('.keras', '.json')
        
        scaler_feat = None
        scaler_tgt = None
        meta = {}
        
        if os.path.exists(scaler_feat_path):
            with open(scaler_feat_path, 'rb') as f:
                scaler_feat = pickle.load(f)
        if os.path.exists(scaler_tgt_path):
            with open(scaler_tgt_path, 'rb') as f:
                scaler_tgt = pickle.load(f)
        if os.path.exists(meta_path):
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta = json.load(f)
        
        suffix = model_key.split('_')[1]
        loaded_models[f'model_{suffix}'] = model
        loaded_models[f'scaler_feat_{suffix}'] = scaler_feat
        loaded_models[f'scaler_tgt_{suffix}'] = scaler_tgt if scaler_tgt else scaler_feat
        loaded_models[f'meta_{suffix}'] = meta
        
        print(f"  âœ… {model_key}: {os.path.basename(model_path)}")
    
    loaded_models['loaded'] = True
    
    if not hasattr(core_system, '_LSTM_MODELS'):
        core_system._LSTM_MODELS = {}
    core_system._LSTM_MODELS.update(loaded_models)
    
    print("  âœ… æ³¨å…¥å®Œæˆ (T+1, T+5, T+20)")
    return True


# =============================================================================
# Step 2: ç‰¹å¾µå·¥ç¨‹ (ä½¿ç”¨ç›¤å¾Œå®Œæ•´è³‡æ–™)
# =============================================================================
def feature_engineering_with_fixed_lstm(workspace: dict, end_date: str) -> tuple:
    """
    ç‰¹å¾µå·¥ç¨‹ (ä½¿ç”¨ç›¤å¾Œå®Œæ•´è³‡æ–™ + Fixed LSTM)
    
    Returns:
        (df, actual_last_date): ç‰¹å¾µ DataFrame å’Œå¯¦éš›æœ€å¾Œæ—¥æœŸ
    """
    print("\n" + "=" * 60)
    print("ğŸ”§ Step 2: ç‰¹å¾µå·¥ç¨‹ (ä½¿ç”¨ç›¤å¾Œå®Œæ•´è³‡æ–™ + Fixed LSTM)")
    print("=" * 60)
    
    # ä½¿ç”¨æœ¬åœ° CSV è¼‰å…¥å®Œæ•´ç›¤å¾Œè³‡æ–™
    print(f"[Data] è¼‰å…¥æœ¬åœ°è³‡æ–™ (2020-01-01 ~ {end_date})...")
    raw_df = core_system._load_local_twii_data(start_date="2020-01-01")
    
    # ç¯©é¸æ—¥æœŸç¯„åœ
    end_dt_ts = pd.Timestamp(end_date)
    raw_df = raw_df[raw_df.index <= end_dt_ts]
    
    actual_last_date = raw_df.index[-1].strftime('%Y-%m-%d')
    print(f"[Data] å¯¦éš›è³‡æ–™æœ€å¾Œæ—¥æœŸ: {actual_last_date}")
    print(f"[Data] è³‡æ–™ç­†æ•¸: {len(raw_df)}")
    
    # åŒ¯å‡ºåŸå§‹æ•¸æ“š CSV
    raw_csv_path = os.path.join(workspace['cache'], 'raw_data.csv')
    raw_df.to_csv(raw_csv_path)
    print(f"[Export] åŸå§‹æ•¸æ“šå·²å­˜æª”: {raw_csv_path}")
    
    # è¨ˆç®—ç‰¹å¾µ
    print(f"[Compute] è¨ˆç®—ç‰¹å¾µä¸­ (ä½¿ç”¨ Fixed LSTM + 30æ¬¡ MC Dropout)...")
    df = core_system.calculate_features(raw_df, raw_df, ticker="^TWII", use_cache=False)
    
    # åŒ¯å‡ºç‰¹å¾µæ•¸æ“š CSV
    features_csv_path = os.path.join(workspace['cache'], 'processed_features.csv')
    df.to_csv(features_csv_path)
    print(f"[Export] ç‰¹å¾µæ•¸æ“šå·²å­˜æª”: {features_csv_path}")
    
    return df, actual_last_date


# =============================================================================
# Step 3: V5 ç­–ç•¥æ¨è«– (ç„¡æ¿¾ç¶²é™åˆ¶)
# =============================================================================
def v5_inference(workspace: dict, df: pd.DataFrame, open_positions: list = None, close_price: float = None) -> dict:
    """
    V5 ç­–ç•¥æ¨è«–
    
    Args:
        workspace: å·¥ä½œå€è³‡è¨Š
        df: ç‰¹å¾µ DataFrame
        open_positions: å¾å›æ¸¬è®€å–çš„ AI æŒå€‰æ¸…å–® (å« buy_price, buy_date)
        close_price: ä»Šæ—¥æ”¶ç›¤åƒ¹ (ç”¨æ–¼è¨ˆç®—å„æŒå€‰å ±é…¬ç‡)
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ Step 3: V5 ç­–ç•¥æ¨è«– (ç„¡æ¿¾ç¶²é™åˆ¶)")
    print("=" * 60)
    
    from stable_baselines3 import PPO
    latest = df.iloc[-1]
    
    # å¦‚æœæ²’å‚³å…¥ close_priceï¼Œå¾ df å–å¾—
    if close_price is None:
        close_price = float(latest['Close'])
    
    # ä¿ç•™ filter è³‡è¨Šä¾›åƒè€ƒï¼Œä½†ä¸å½±éŸ¿è²·å…¥æ±ºç­–
    signal_buy_filter = bool(latest.get('Signal_Buy_Filter', False))
    print(f"  [æ¿¾ç¶²] Signal_Buy_Filter = {signal_buy_filter} (åƒ…ä¾›åƒè€ƒï¼ŒV5ä¸å—é™)")
    
    features = np.array([latest.get(col, 0.0) for col in core_system.FEATURE_COLS], dtype=np.float32).reshape(1, -1)
    features = np.nan_to_num(features, nan=0.0, posinf=1.0, neginf=-1.0)
    
    # è¼‰å…¥ V5 æ¨¡å‹
    buy_path = os.path.join(V5_MODEL_PATH, 'ppo_buy_twii_final.zip')
    sell_path = os.path.join(V5_MODEL_PATH, 'ppo_sell_twii_final.zip')
    
    if not os.path.exists(buy_path):
        return {'error': 'V5 Model not found', 'filter_signal': signal_buy_filter}

    try:
        buy_agent = PPO.load(buy_path)
        sell_agent = PPO.load(sell_path)
        
        # ===== Buy Agent =====
        b_act, _ = buy_agent.predict(features, deterministic=True)
        b_obs = buy_agent.policy.obs_to_tensor(features)[0]
        b_prob = buy_agent.policy.get_distribution(b_obs).distribution.probs.detach().cpu().numpy()[0]
        
        ai_action = 'BUY' if b_act[0] == 1 else 'WAIT'
        buy_prob = float(b_prob[1]) if b_act[0] == 1 else float(b_prob[0])
        
        # V5: ç„¡æ¿¾ç¶²é™åˆ¶ï¼Œç›´æ¥ä½¿ç”¨ AI æ±ºç­–
        buy_signal = ai_action
        filter_note = "âœ…é€šé" if signal_buy_filter else "âŒæœªé€šé"
        print(f"  [V5] Buy: {buy_signal} ({buy_prob:.1%}) | æ¿¾ç¶²: {filter_note}")
        
        # ===== Sell Agent (çœŸå¯¦æŒå€‰åˆ†æ) =====
        position_decisions = []
        
        if open_positions and len(open_positions) > 0:
            print(f"  [V5] åˆ†æ {len(open_positions)} ç­† AI æŒå€‰...")
            
            for pos in open_positions:
                buy_price = float(pos.get('buy_price', 0))
                buy_date = pos.get('buy_date', 'N/A')
                
                if buy_price > 0:
                    # è¨ˆç®—çœŸå¯¦å ±é…¬ç‡
                    current_return = close_price / buy_price
                    return_pct = (current_return - 1) * 100
                    
                    # æ§‹å»º Sell Agent çš„è§€å¯Ÿå€¼ (ç‰¹å¾µ + å ±é…¬ç‡)
                    s_feat = np.concatenate([features[0], [current_return]]).reshape(1, -1).astype(np.float32)
                    s_act, _ = sell_agent.predict(s_feat, deterministic=True)
                    
                    # å–å¾—æ©Ÿç‡åˆ†å¸ƒä»¥è¨ˆç®—ä¿¡å¿ƒ
                    s_obs = sell_agent.policy.obs_to_tensor(s_feat)[0]
                    s_prob = sell_agent.policy.get_distribution(s_obs).distribution.probs.detach().cpu().numpy()[0]
                    
                    sell_action = 'SELL' if s_act[0] == 1 else 'HOLD'
                    sell_conf = float(s_prob[1]) if s_act[0] == 1 else float(s_prob[0])
                    
                    # åˆ¤æ–·æ˜¯å¦è§¸ç™¼åœæ (ç¡¬æ€§è¦å‰‡: -8%)
                    triggered_stop_loss = current_return < 0.92
                    
                    position_decisions.append({
                        'buy_date': buy_date,
                        'buy_price': buy_price,
                        'current_return': current_return,
                        'return_pct': return_pct,
                        'action': sell_action,
                        'confidence': sell_conf,
                        'triggered_stop_loss': triggered_stop_loss,
                        'final_action': 'SELL' if triggered_stop_loss else sell_action
                    })
        else:
            print(f"  [V5] ç„¡ AI æŒå€‰ï¼Œè·³é Sell Agent åˆ†æ")
        
        return {
            'filter_signal': signal_buy_filter,
            'buy_decision': buy_signal,
            'buy_confidence': buy_prob * 100,
            'buy_action': int(b_act[0]),
            'ai_action': ai_action,
            'position_decisions': position_decisions  # æ–°å¢ï¼šæ¯ç­†æŒå€‰çš„ Sell Agent åˆ¤æ–·
        }
    except Exception as e:
        print(f"  [Error] V5 Inference: {e}")
        return {'error': str(e), 'filter_signal': signal_buy_filter}


# =============================================================================
# Step 4: è¼¸å‡ºå ±å‘Š
# =============================================================================
def generate_report(workspace: dict, df: pd.DataFrame, res: dict, date_str: str, 
                    backtest_status: dict = None):
    print("\n" + "=" * 60)
    print("ğŸ“Š Step 4: ç›¤å¾Œåˆ†æå ±å‘Š (V5 Fixed LSTM)")
    print("=" * 60)
    
    last = df.iloc[-1]
    filter_status = res.get('filter_signal', False)
    close_price = float(last['Close'])
    volume = float(last.get('Volume', 0))
    
    lines = []
    lines.append("=" * 50)
    lines.append(f"ğŸ“… V5 ç›¤å¾Œåˆ†æå ±å‘Š - {date_str}")
    lines.append(f"â° æ›´æ–°æ™‚é–“: {datetime.now().strftime('%H:%M:%S')}")
    lines.append("=" * 50)
    lines.append(f"ğŸ“Š Open:  {last['Open']:,.2f}")
    lines.append(f"ğŸ“ˆ High:  {last['High']:,.2f}")
    lines.append(f"ğŸ“‰ Low:   {last['Low']:,.2f}")
    lines.append(f"ğŸ’° Close: {close_price:,.2f} (æ”¶ç›¤)")
    lines.append(f"ğŸ“¦ Volume: {volume:.2f} å„„å…ƒ")
    lines.append("-" * 50)
    
    # æ¿¾ç¶²ç‹€æ…‹ (åƒ…ä¾›åƒè€ƒ)
    filter_icon = "âœ…" if filter_status else "ğŸš«"
    lines.append(f"ğŸ“‹ [æ¿¾ç¶²ç‹€æ…‹] {filter_icon} {'é€šé' if filter_status else 'æœªé€šé'} (V5ä¸å—æ­¤é™åˆ¶)")
    lines.append("-" * 50)
    
    # æ§“æ¡¿ç‹€æ…‹ (Strategy 1 Only)
    if backtest_status and 'leveraged_mode' in backtest_status:
        lev_mode = backtest_status['leveraged_mode']
        peak_price = backtest_status.get('peak_price', 0)
        
        lev_icon = "ğŸ”¥" if lev_mode else "â„ï¸"
        lev_str = "ON (2å€æ§“æ¡¿)" if lev_mode else "OFF (1å€æ§“æ¡¿)"
        
        lines.append(f"âš¡ [2x æ§“æ¡¿ç›£æ§] (Strategy 1)")
        lines.append(f"   ç‹€æ…‹: {lev_icon} {lev_str}")
        
        if peak_price > 0:
            dd_pct = (close_price - peak_price) / peak_price
            lines.append(f"   é«˜é»: {peak_price:,.2f} | ç›®å‰è·Œå¹…: {dd_pct*100:.2f}%")
            if not lev_mode:
                trigger_price = peak_price * 0.92  # 8% threshold
                dist_to_trigger = (close_price - trigger_price) / close_price
                lines.append(f"   è§¸ç™¼: {trigger_price:,.2f} (è·é›¢: {dist_to_trigger*100:.2f}%)")
            else:
                lines.append(f"   é€€å‡º: {peak_price:,.2f} (å›åˆ°é«˜é»å³é€€å‡º)")
        lines.append("-" * 50)

    # LSTM
    lines.append("ğŸ”® [åˆ†æå¸« LSTM] (Fixed æ¨¡å‹)")
    pred_1d_pct = last.get('LSTM_Pred_1d', 0)
    price_1d = close_price * (1 + pred_1d_pct)
    
    pred_5d_pct = last.get('LSTM_Pred_5d', 0)
    price_5d = close_price * (1 + pred_5d_pct)
    
    pred_20d_pct = last.get('LSTM_Pred_20d', 0)
    price_20d = close_price * (1 + pred_20d_pct)

    lines.append(f"   T+1 é æ¸¬: {pred_1d_pct*100:+.2f}% (ç›®æ¨™åƒ¹: {price_1d:,.2f}) | ä¿¡å¿ƒåº¦: {last.get('LSTM_Conf_1d', 0)*100:.1f}%")
    lines.append(f"   T+5 é æ¸¬: {pred_5d_pct*100:+.2f}% (ç›®æ¨™åƒ¹: {price_5d:,.2f}) | ä¿¡å¿ƒåº¦: {last.get('LSTM_Conf_5d', 0)*100:.1f}%")
    lines.append(f"   T+20 é æ¸¬: {pred_20d_pct*100:+.2f}% (ç›®æ¨™åƒ¹: {price_20d:,.2f}) | ä¿¡å¿ƒåº¦: {last.get('LSTM_Conf_20d', 0)*100:.1f}%")
    lines.append("-" * 50)

    # V5 é¡¯æ€§ç‰¹å¾µ
    lines.append("ğŸ“ [é—œéµç‰¹å¾µ]")
    lines.append(f"   MA20 å‹•èƒ½: {last.get('Feat_MA20_Slope', 0)*100:+.2f}%  (>0 è½‰å¼·)")
    lines.append(f"   å¸‚å ´é«”åˆ¶: {last.get('Feat_Trend_Gap', 0)*100:+.2f}%  (>0 å¤šé ­çµæ§‹)")
    lines.append(f"   çŸ­ç·šä¹–é›¢: {last.get('Feat_Bias_MA20', 0)*100:+.2f}%")
    lines.append(f"   å­£ç·šè·é›¢: {last.get('Feat_Dist_MA60', 0)*100:+.2f}%")
    lines.append(f"   å¹´ç·šä½ç½®: {last.get('Feat_Dist_MA240', 0)*100:+.2f}%  (>0 é•·å¤š)")
    lines.append(f"   ç›¸å°é‡èƒ½: {last.get('Feat_Vol_Ratio', 0):.2f}x   (>1.0 æ”¾é‡)")
    lines.append("-" * 50)
    
    # V5 RL
    lines.append("ğŸ¤– [æ“ç›¤æ‰‹ V5] (å°ç¨±çå‹µ + ç„¡æ¿¾ç¶²)")
    if 'error' in res:
        lines.append(f"   âŒ éŒ¯èª¤: {res['error']}")
    else:
        buy_signal = res.get('buy_decision', 'N/A')
        buy_prob = res.get('buy_confidence', 0) / 100
        ai_action = res.get('ai_action', 'WAIT')
        buy_icon = "ğŸš€" if ai_action == 'BUY' else "ğŸ’¤" if ai_action == 'WAIT' else "ğŸš«"
        
        lines.append(f"   ğŸ›’ è²·å…¥è¨Šè™Ÿ: {buy_icon} {buy_signal} ({buy_prob:.1%})")

    lines.append("-" * 50)
    
    # Advice (V5: ç„¡æ¿¾ç¶²é™åˆ¶)
    ai_action = res.get('ai_action', 'N/A')
    if ai_action == 'BUY':
        advice = "â­â­ V5 å¼·åŠ›è²·é€² (Strong Buy) â­â­"
    elif ai_action == 'WAIT':
        advice = "ğŸ’¤ ç©ºæ‰‹è§€æœ› (Wait)"
    else:
        advice = "â“ è¨Šè™Ÿä¸æ˜"
    
    # é¡å¤–æ¨™æ³¨æ¿¾ç¶²ç‹€æ…‹ä¾›åƒè€ƒ
    filter_note = "æ¿¾ç¶²âœ…" if filter_status else "æ¿¾ç¶²âŒ"
    advice += f" [{filter_note}]"
        
    lines.append(f"ğŸ’¡ ç›¤å¾Œå»ºè­°: {advice}")
    lines.append("-" * 50)
    
    # å›æ¸¬æŒå€‰ç‹€æ…‹
    if backtest_status and backtest_status.get('found'):
        csv_file = backtest_status.get('csv_file', 'N/A')
        date_match = re.search(r'(\d{8})_(\d{8})\.csv$', csv_file)
        if date_match:
            start_date = f"{date_match.group(1)[:4]}-{date_match.group(1)[4:6]}-{date_match.group(1)[6:8]}"
            end_date = f"{date_match.group(2)[:4]}-{date_match.group(2)[4:6]}-{date_match.group(2)[6:8]}"
            date_range_str = f"{start_date} ~ {end_date}"
        else:
            date_range_str = csv_file
        
        lines.append(f"ğŸ’¼ [å›æ¸¬æŒå€‰ç‹€æ…‹] æª”æ¡ˆ: {csv_file}")
        lines.append(f"   ğŸ“… å›æ¸¬æœŸé–“: {date_range_str}")
        lines.append(f"   ğŸ›ï¸  DCA å€‰ä½: {backtest_status['dca_positions']} å€‰")
        lines.append(f"   ğŸ¤– AI å€‰ä½: {backtest_status['ai_positions']} å€‰")
        lines.append(f"   ğŸ“Š ç¸½å€‰æ•¸: {backtest_status['total_positions']} å€‰")
        lines.append(f"   ğŸ“ æœ€å¾Œæ“ä½œ: {backtest_status.get('note', 'N/A')}")
        
        # é æ¸¬ä»Šæ—¥æ“ä½œ
        lines.append("-" * 50)
        lines.append("ğŸ”® [ä»Šæ—¥é æ¸¬] (åŸºæ–¼æ”¶ç›¤åƒ¹)")
        
        ai_positions = backtest_status['ai_positions']
        dca_positions = backtest_status['dca_positions']
        
        # é æ¸¬è²·å…¥ (V5: ç„¡æ¿¾ç¶²é™åˆ¶ï¼Œç´”çœ‹ AI æ±ºç­–)
        predicted_buy = 0
        if ai_action == 'BUY':
            lines.append(f"   ğŸŸ¢ è²·å…¥é æ¸¬: AI+1å€‰ (V5 ç„¡æ¿¾ç¶²é™åˆ¶, AIå»ºè­°BUY)")
            predicted_buy = 1
        else:
            lines.append(f"   âšª è²·å…¥é æ¸¬: ç„¡ (AI:{ai_action})")
        
        # é æ¸¬è³£å‡º (ä½¿ç”¨ position_decisions)
        position_decisions = res.get('position_decisions', [])
        predicted_sell = 0
        
        if position_decisions:
            lines.append("-" * 50)
            lines.append("ğŸ“¦ [AIæŒå€‰æ˜ç´° + Sell Agent åˆ¤æ–·]")
            
            for i, pd in enumerate(position_decisions, 1):
                buy_date = pd.get('buy_date', 'N/A')
                buy_price = pd.get('buy_price', 0)
                return_pct = pd.get('return_pct', 0)
                action = pd.get('action', 'HOLD')
                confidence = pd.get('confidence', 0)
                final_action = pd.get('final_action', 'HOLD')
                triggered_stop_loss = pd.get('triggered_stop_loss', False)
                
                # æ±ºå®šé¡¯ç¤ºæ ¼å¼
                if triggered_stop_loss:
                    status_icon = "ğŸ”´ SELL"
                    reason = f"åœæè§¸ç™¼ (AI: {action} {confidence:.1%})"
                elif final_action == 'SELL':
                    status_icon = "ğŸ”´ SELL"
                    reason = f"AIæ±ºå®š ({confidence:.1%})"
                else:
                    status_icon = "ğŸŸ¢ HOLD"
                    reason = f"AIæ±ºå®š ({confidence:.1%})"
                
                lines.append(f"   #{i} è²·å…¥: {buy_date} @ {buy_price:,.2f}")
                lines.append(f"       å ±é…¬: {return_pct:+.2f}% | {status_icon} {reason}")
                
                if final_action == 'SELL':
                    predicted_sell += 1
        elif ai_positions > 0:
            lines.append(f"   âš ï¸ ç„¡æŒå€‰æ˜ç´°è³‡æ–™")
        else:
            lines.append(f"   âšª è³£å‡ºé æ¸¬: ç„¡ (AI ç„¡æŒå€‰)")
        
        # è¨ˆç®—é ä¼°ç¸½å€‰
        predicted_ai = ai_positions + predicted_buy - predicted_sell
        predicted_total = dca_positions + predicted_ai
        
        lines.append("-" * 50)
        lines.append("ğŸ“Š [é ä¼°æ˜æ—¥å€‰ä½]")
        lines.append(f"   DCA: {dca_positions} å€‰ (ä¸è®Š)")
        change = predicted_buy - predicted_sell
        change_str = f"+{change}" if change > 0 else str(change) if change < 0 else "Â±0"
        lines.append(f"   AI:  {ai_positions} â†’ {predicted_ai} å€‰ ({change_str})")
        lines.append(f"   ç¸½è¨ˆ: {backtest_status['total_positions']} â†’ {predicted_total} å€‰")
        
    else:
        lines.append("ğŸ’¼ [å›æ¸¬æŒå€‰ç‹€æ…‹] æœªæ‰¾åˆ°å›æ¸¬çµæœ")
        lines.append("   è«‹å…ˆåŸ·è¡Œ: python backtest_v5_dca_hybrid_no_filter_fixed_lstm.py --start 2025-01-02")
    
    lines.append("=" * 50)
    
    report = "\n".join(lines)
    print(report)
    
    # Save
    with open(os.path.join(workspace['reports'], 'daily_summary.txt'), 'w', encoding='utf-8') as f:
        f.write(report)
    
    json_data = {
        'date': date_str,
        'filter_status': filter_status,
        'market': {'close': close_price, 'volume': volume},
        'lstm': {
            'pred_1d': float(pred_1d_pct), 'price_1d': float(price_1d),
            'pred_5d': float(pred_5d_pct), 'price_5d': float(price_5d),
            'pred_20d': float(pred_20d_pct), 'price_20d': float(price_20d),
        },
        'v5': res,
        'advice': advice
    }
    with open(os.path.join(workspace['reports'], 'daily_summary.json'), 'w', encoding='utf-8') as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)
    
    print(f"\n[Report] å·²å„²å­˜è‡³: {workspace['reports']}")


# =============================================================================
# Main
# =============================================================================
def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='V5 ç›¤å¾Œåˆ†æç³»çµ± (Fixed LSTM + No Filter)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ç¯„ä¾‹:
  python daily_ops_v5_fixed_lstm.py                    # ä½¿ç”¨æœ€æ–°å›æ¸¬çµæœ
  python daily_ops_v5_fixed_lstm.py -i                 # äº’å‹•å¼é¸æ“‡å›æ¸¬ CSV
  python daily_ops_v5_fixed_lstm.py --backtest-start 2025-01-02  # æŒ‡å®šå›æ¸¬èµ·å§‹æ—¥
        '''
    )
    parser.add_argument(
        '-i', '--interactive',
        action='store_true',
        help='äº’å‹•å¼é¸æ“‡å›æ¸¬ CSV æª”æ¡ˆ (ä½¿ç”¨æ–¹å‘éµ)'
    )
    parser.add_argument(
        '--backtest-start', 
        type=str, 
        default=None,
        help='å›æ¸¬èµ·å§‹æ—¥æœŸ (YYYY-MM-DD æˆ– YYYYMMDD æ ¼å¼)'
    )
    args = parser.parse_args()
    
    # è¨ˆç®—ä»Šå¤©æ—¥æœŸ (æ’é™¤é€±æœ«)
    today = datetime.now()
    if today.weekday() == 5:  # Saturday
        today -= timedelta(days=1)
    elif today.weekday() == 6:  # Sunday
        today -= timedelta(days=2)
    
    date_str = today.strftime('%Y-%m-%d')
    
    print("=" * 60)
    print(f"ğŸš€ V5 ç›¤å¾Œåˆ†æç³»çµ± (Fixed LSTM + No Filter) - {date_str}")
    print("=" * 60)
    
    # æª¢æŸ¥ V5 æ¨¡å‹
    if not os.path.exists(os.path.join(V5_MODEL_PATH, 'ppo_buy_twii_final.zip')):
        print(f"\n[Error] V5 æ¨¡å‹ä¸å­˜åœ¨: {V5_MODEL_PATH}")
        print("è«‹å…ˆåŸ·è¡Œ train_v5_models.py å®Œæˆè¨“ç·´")
        sys.exit(1)
    
    # Step 0: å»ºç«‹å·¥ä½œå€
    ws = create_daily_workspace(date_str)
    
    # Step 0.5: è®€å–å›æ¸¬æŒå€‰ç‹€æ…‹
    print("\n[Backtest] è®€å–å›æ¸¬æŒå€‰ç‹€æ…‹...")
    backtest_status = load_latest_backtest_status(args.backtest_start, interactive=args.interactive)
    
    # Step 1: è®€å– Fixed LSTM è³‡è¨Š
    print("\n" + "=" * 60)
    print("ğŸ“š Step 1: è¼‰å…¥ Fixed LSTM æ¨¡å‹ (ä¸é‡è¨“)")
    print("=" * 60)
    
    lstm_info = load_lstm_info_from_backtest(backtest_status.get('csv_file'))
    if not lstm_info:
        print("[Error] ç„¡æ³•è¼‰å…¥ LSTM è³‡è¨Š")
        sys.exit(1)
    
    if not load_fixed_lstm_models(lstm_info):
        print("[Error] ç„¡æ³•è¼‰å…¥ Fixed LSTM æ¨¡å‹")
        sys.exit(1)
    
    # Step 2: ç‰¹å¾µå·¥ç¨‹ (ä½¿ç”¨ç›¤å¾Œå®Œæ•´è³‡æ–™)
    df, actual_date = feature_engineering_with_fixed_lstm(ws, date_str)
    
    if actual_date != date_str:
        print(f"[Warning] é ä¼°æ—¥æœŸ {date_str} èˆ‡å¯¦éš›è³‡æ–™æ—¥æœŸ {actual_date} ä¸åŒ")
        print(f"[Info] å ±å‘Šå°‡ä½¿ç”¨å¯¦éš›è³‡æ–™æ—¥æœŸ: {actual_date}")
    
    # Step 3: V5 ç­–ç•¥æ¨è«– (å‚³å…¥çœŸå¯¦æŒå€‰è³‡è¨Š)
    open_positions = backtest_status.get('open_positions', []) if backtest_status else []
    close_price = float(df.iloc[-1]['Close'])
    res = v5_inference(ws, df, open_positions=open_positions, close_price=close_price)
    
    # Step 4: è¼¸å‡ºå ±å‘Š
    generate_report(ws, df, res, actual_date, backtest_status)
    
    print("\n" + "=" * 60)
    print("âœ… V5 ç›¤å¾Œåˆ†æå®Œæˆ (Fixed LSTM + No Filter)ï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
